#!/usr/bin/env python3
"""
Enhanced H3 Geospatial Fusion Module for Cascadia Agricultural Analysis Framework

This module provides comprehensive H3 v4 geospatial data fusion with:
- Proper H3 v4 API usage throughout
- Advanced spatial analysis and correlation
- SPACE integration for enhanced operations
- Real-time data fusion capabilities
- Comprehensive validation and quality control
"""

import logging
import json
import hashlib
from pathlib import Path
import numpy as np
import pandas as pd
from typing import Dict, Any, List, Optional, Tuple, Union
from datetime import datetime
import geopandas as gpd
from shapely.geometry import Polygon, Point, MultiPolygon
from shapely.ops import unary_union
import h3

# Import SPACE utilities for enhanced geospatial operations
try:
    from geo_infer_space.utils.h3_utils import (
        latlng_to_cell,
        cell_to_latlng,
        cell_to_latlng_boundary,
        geo_to_cells,
        polygon_to_cells,
        grid_disk,
        grid_distance,
        cell_area,
        get_resolution,
        is_valid_cell,
        are_neighbor_cells
    )
    SPACE_H3_AVAILABLE = True
except ImportError:
    SPACE_H3_AVAILABLE = False
    # Fallback to direct h3 package with proper v4 API usage
    def latlng_to_cell(lat, lng, resolution): return h3.latlng_to_cell(lat, lng, resolution)
    def cell_to_latlng(cell): return h3.cell_to_latlng(cell)
    def cell_to_latlng_boundary(cell): return h3.cell_to_boundary(cell)
    def geo_to_cells(geojson, resolution): return h3.polygon_to_cells(geojson, resolution)
    def polygon_to_cells(polygon, resolution): return h3.polygon_to_cells(polygon, resolution)
    def grid_disk(cell, k): return h3.grid_disk(cell, k)
    def grid_distance(cell1, cell2): return h3.grid_distance(cell1, cell2)
    def cell_area(cell, unit='km^2'): return h3.cell_area(cell, unit=unit)
    def get_resolution(cell): return h3.get_resolution(cell)
    def is_valid_cell(cell): return h3.is_valid_cell(cell)
    def are_neighbor_cells(cell1, cell2): return h3.are_neighbor_cells(cell1, cell2)

logger = logging.getLogger(__name__)

class EnhancedH3Fusion:
    """
    Enhanced H3 geospatial fusion engine for Cascadia agricultural analysis.
    
    Features:
    - Real H3 v4 API usage throughout
    - Advanced spatial analysis and correlation
    - SPACE integration for enhanced operations
    - Comprehensive data validation
    - Real-time fusion capabilities
    """
    
    def __init__(self, h3_resolution: int = 8, enable_spatial_analysis: bool = True, cache_dir: Optional[Path] = None):
        """
        Initialize the enhanced H3 fusion engine.
        
        Args:
            h3_resolution: H3 resolution for spatial indexing
            enable_spatial_analysis: Enable advanced spatial analysis
        """
        self.h3_resolution = h3_resolution
        self.enable_spatial_analysis = enable_spatial_analysis
        self.cache_dir = Path(cache_dir) if cache_dir else None
        
        # Validation settings
        self.validation_settings = {
            'min_hexagon_count': 1,
            'max_hexagon_count': 1000000,
            'require_valid_geometries': True,
            'spatial_consistency_check': True,
            'data_quality_threshold': 0.8
        }
        
        logger.info(f"Enhanced H3 Fusion initialized with resolution {h3_resolution}")
        logger.info(f"SPACE H3 utilities available: {SPACE_H3_AVAILABLE}")
        logger.info(f"Spatial analysis enabled: {enable_spatial_analysis}")
        if self.cache_dir:
            try:
                self.cache_dir.mkdir(parents=True, exist_ok=True)
                logger.info(f"Fusion cache directory: {self.cache_dir}")
            except Exception as e:
                logger.warning(f"Could not create fusion cache directory {self.cache_dir}: {e}")
    
    def fuse_geospatial_data(self, data_sources: Dict[str, Any], 
                           target_hexagons: List[str]) -> Dict[str, Any]:
        """
        Fuse multiple geospatial data sources into unified H3-indexed format.
        
        Args:
            data_sources: Dictionary of data sources with their H3 data
            target_hexagons: List of target H3 hexagons
            
        Returns:
            Fused H3-indexed data dictionary
        """
        logger.info(f"Starting enhanced H3 geospatial fusion for {len(data_sources)} data sources")
        
        # Validate input data
        validation_result = self._validate_fusion_inputs(data_sources, target_hexagons)
        if not validation_result['is_valid']:
            logger.error(f"Fusion validation failed: {validation_result['errors']}")
            return {}
        
        # Initialize fused data structure
        fused_data = {}
        
        # Process each data source
        for source_name, source_data in data_sources.items():
            logger.info(f"Processing data source: {source_name}")
            
            try:
                # Validate source data
                source_validation = self._validate_source_data(source_data, source_name)
                if not source_validation['is_valid']:
                    logger.warning(f"Source {source_name} validation failed: {source_validation['errors']}")
                    continue
                
                # Fuse source data into target hexagons
                fused_source_data = self._fuse_source_to_target_hexagons(
                    source_data, target_hexagons, source_name
                )
                
                # Add to fused data
                for hex_id, hex_data in fused_source_data.items():
                    if hex_id not in fused_data:
                        fused_data[hex_id] = {}
                    fused_data[hex_id][source_name] = hex_data
                
                logger.info(f"âœ… Fused {source_name}: {len(fused_source_data)} hexagons")
                
            except Exception as e:
                logger.error(f"âŒ Failed to fuse {source_name}: {e}")
                continue
        
        # Perform spatial analysis if enabled
        if self.enable_spatial_analysis and fused_data:
            logger.info("Performing enhanced spatial analysis...")
            fused_data = self._perform_spatial_analysis(fused_data, target_hexagons)
        
        # Generate fusion report
        fusion_report = self._generate_fusion_report(fused_data, data_sources, target_hexagons)
        
        logger.info(f"âœ… Enhanced H3 fusion completed: {len(fused_data)} hexagons")
        logger.info(f"ðŸ“Š Fusion coverage: {len(fused_data) / len(target_hexagons) * 100:.1f}%")
        
        return fused_data

    # -------------------- Caching Utilities --------------------
    def _compute_fusion_signature(self, data_sources: Dict[str, Any], target_hexagons: List[str]) -> str:
        """Compute a deterministic cache key for fusion inputs.

        Uses module names, per-module hex counts, feature counts, a small sample of hex ids,
        target set size, resolution, and spatial analysis flag.
        """
        try:
            signature_obj: Dict[str, Any] = {
                'h3_resolution': int(self.h3_resolution),
                'spatial': bool(self.enable_spatial_analysis),
                'target_count': int(len(target_hexagons)),
                'modules': {}
            }
            for module_name in sorted(data_sources.keys()):
                mod = data_sources.get(module_name) or {}
                if not isinstance(mod, dict):
                    mod = {}
                hex_ids = sorted(list(mod.keys()))
                feature_count = 0
                for v in mod.values():
                    if isinstance(v, list):
                        feature_count += len(v)
                    else:
                        feature_count += 1
                sample = hex_ids[:50] + hex_ids[-50:]
                signature_obj['modules'][module_name] = {
                    'hex_count': len(mod),
                    'feature_count': feature_count,
                    'sample_hexes': sample
                }
            serialized = json.dumps(signature_obj, sort_keys=True).encode('utf-8')
            return hashlib.sha256(serialized).hexdigest()[:16]
        except Exception as e:
            logger.warning(f"Failed to compute fusion signature, using fallback: {e}")
            return f"res{self.h3_resolution}_fallback"

    def _get_cache_file(self, cache_key: str) -> Optional[Path]:
        if not self.cache_dir:
            return None
        return self.cache_dir / f"fused_res{self.h3_resolution}_{cache_key}.json"

    def load_fusion_cache(self, data_sources: Dict[str, Any], target_hexagons: List[str]) -> Optional[Dict[str, Any]]:
        """Attempt to load fused data from cache based on inputs."""
        if not self.cache_dir:
            return None
        cache_key = self._compute_fusion_signature(data_sources, target_hexagons)
        cache_file = self._get_cache_file(cache_key)
        if not cache_file or not cache_file.exists():
            return None
        try:
            with open(cache_file, 'r') as f:
                payload = json.load(f)
            fused_data = payload.get('fused_data', {})
            logger.info(f"Loaded fusion cache: {cache_file} ({len(fused_data)} hexes)")
            return fused_data
        except Exception as e:
            logger.warning(f"Failed to load fusion cache {cache_file}: {e}")
            return None

    def save_fusion_cache(self, data_sources: Dict[str, Any], target_hexagons: List[str], fused_data: Dict[str, Any], report: Optional[Dict[str, Any]] = None) -> Optional[Path]:
        """Persist fused data and report to cache."""
        if not self.cache_dir:
            return None
        try:
            cache_key = self._compute_fusion_signature(data_sources, target_hexagons)
            cache_file = self._get_cache_file(cache_key)
            if not cache_file:
                return None
            payload = {
                'meta': {
                    'h3_resolution': int(self.h3_resolution),
                    'spatial_analysis': bool(self.enable_spatial_analysis),
                    'modules': list(sorted(data_sources.keys())),
                    'target_hexagon_count': int(len(target_hexagons)),
                    'fused_hexagon_count': int(len(fused_data))
                },
                'fused_data': fused_data,
                'report': report or {}
            }
            with open(cache_file, 'w') as f:
                json.dump(payload, f)
            logger.info(f"Saved fusion cache: {cache_file}")
            return cache_file
        except Exception as e:
            logger.warning(f"Failed to save fusion cache: {e}")
            return None
    
    def _validate_fusion_inputs(self, data_sources: Dict[str, Any], 
                               target_hexagons: List[str]) -> Dict[str, Any]:
        """
        Validate fusion inputs for consistency and quality.
        
        Args:
            data_sources: Dictionary of data sources
            target_hexagons: List of target hexagons
            
        Returns:
            Validation result dictionary
        """
        validation_result = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'source_count': len(data_sources),
            'target_hexagon_count': len(target_hexagons)
        }
        
        # Validate target hexagons
        if not target_hexagons:
            validation_result['is_valid'] = False
            validation_result['errors'].append("No target hexagons provided")
        
        # Validate hexagon format
        invalid_hexagons = []
        for hex_id in target_hexagons:
            if not is_valid_cell(hex_id):
                invalid_hexagons.append(hex_id)
        
        if invalid_hexagons:
            validation_result['is_valid'] = False
            validation_result['errors'].append(f"Invalid hexagons: {invalid_hexagons[:5]}")
        
        # Validate data sources
        if not data_sources:
            validation_result['warnings'].append("No data sources provided")
        
        for source_name, source_data in data_sources.items():
            if not isinstance(source_data, dict):
                validation_result['errors'].append(f"Invalid source data type for {source_name}")
            elif len(source_data) == 0:
                validation_result['warnings'].append(f"Empty source data for {source_name}")
        
        return validation_result
    
    def _validate_source_data(self, source_data: Dict[str, Any], source_name: str) -> Dict[str, Any]:
        """
        Validate individual source data.
        
        Args:
            source_data: Source data dictionary
            source_name: Name of the source
            
        Returns:
            Validation result dictionary
        """
        validation_result = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'hexagon_count': len(source_data),
            'feature_count': 0
        }
        
        # Count total features
        for hex_data in source_data.values():
            if isinstance(hex_data, list):
                validation_result['feature_count'] += len(hex_data)
            elif isinstance(hex_data, dict):
                validation_result['feature_count'] += 1
        
        # Check for reasonable data size
        if len(source_data) > self.validation_settings['max_hexagon_count']:
            validation_result['warnings'].append(f"Large dataset: {len(source_data)} hexagons")
        
        if len(source_data) < self.validation_settings['min_hexagon_count']:
            validation_result['warnings'].append(f"Small dataset: {len(source_data)} hexagons")
        
        return validation_result
    
    def _fuse_source_to_target_hexagons(self, source_data: Dict[str, Any], 
                                       target_hexagons: List[str], 
                                       source_name: str) -> Dict[str, Any]:
        """
        Fuse source data to target hexagons using H3 spatial operations.
        
        Args:
            source_data: Source H3 data
            target_hexagons: List of target hexagons
            source_name: Name of the source
            
        Returns:
            Fused data for target hexagons
        """
        fused_data = {}
        target_hex_set = set(target_hexagons)
        
        # Process each source hexagon with periodic progress logging
        total = len(source_data)
        next_log_at = 0
        processed = 0
        matched_total = 0
        for source_hex_id, source_hex_data in source_data.items():
            try:
                # Validate source hexagon
                if not is_valid_cell(source_hex_id):
                    logger.warning(f"Invalid source hexagon: {source_hex_id}")
                    continue
                
                # Find target hexagons that intersect with source hexagon
                intersecting_targets = self._find_intersecting_hexagons(
                    source_hex_id, target_hex_set, source_name
                )
                
                # Distribute source data to intersecting targets
                for target_hex_id in intersecting_targets:
                    if target_hex_id not in fused_data:
                        fused_data[target_hex_id] = []
                    
                    # Add source data to target
                    if isinstance(source_hex_data, list):
                        fused_data[target_hex_id].extend(source_hex_data)
                    else:
                        fused_data[target_hex_id].append(source_hex_data)
                matched_total += len(intersecting_targets)
                
            except Exception as e:
                logger.warning(f"Error processing source hexagon {source_hex_id}: {e}")
                continue
            finally:
                processed += 1
                if processed >= next_log_at:
                    logger.info(f"[{source_name}] fused {processed}/{total} source hexes; matched targets so far: {matched_total}")
                    # Log roughly every 5% of progress, but at least every 1000
                    step = max(1000, total // 20)
                    next_log_at = processed + step
        
        logger.info(f"[{source_name}] fusion complete: processed={processed}, targets_matched={matched_total}")
        return fused_data
    
    def _find_intersecting_hexagons(self, source_hex_id: str, target_hex_set: set, 
                                   source_name: str) -> List[str]:
        """
        Find target hexagons that intersect with a source hexagon.
        
        Args:
            source_hex_id: Source H3 hexagon ID
            target_hex_set: Set of target hexagon IDs
            source_name: Name of the source for logging
            
        Returns:
            List of intersecting target hexagon IDs
        """
        try:
            # Get source hexagon boundary (lat, lng) and convert to (lng, lat) for shapely
            source_boundary = cell_to_latlng_boundary(source_hex_id)
            source_coords = [(lng, lat) for (lat, lng) in source_boundary]
            # Ensure closed ring
            if source_coords and source_coords[0] != source_coords[-1]:
                source_coords.append(source_coords[0])
            source_polygon = Polygon(source_coords)
            
            # Find target hexagons that intersect
            intersecting_targets = []
            
            for target_hex_id in target_hex_set:
                try:
                    # Get target hexagon boundary and convert to (lng, lat)
                    target_boundary = cell_to_latlng_boundary(target_hex_id)
                    target_coords = [(lng, lat) for (lat, lng) in target_boundary]
                    if target_coords and target_coords[0] != target_coords[-1]:
                        target_coords.append(target_coords[0])
                    target_polygon = Polygon(target_coords)
                    
                    # Check for intersection
                    if source_polygon.intersects(target_polygon):
                        intersecting_targets.append(target_hex_id)
                        
                except Exception as e:
                    logger.warning(f"Error checking intersection for {target_hex_id}: {e}")
                    continue
            
            return intersecting_targets
            
        except Exception as e:
            logger.warning(f"Error finding intersecting hexagons for {source_hex_id}: {e}")
            return []
    
    def _perform_spatial_analysis(self, fused_data: Dict[str, Any], 
                                 target_hexagons: List[str]) -> Dict[str, Any]:
        """
        Perform enhanced spatial analysis on fused data.
        
        Args:
            fused_data: Fused H3 data
            target_hexagons: List of target hexagons
            
        Returns:
            Enhanced fused data with spatial analysis
        """
        logger.info("Performing enhanced spatial analysis...")
        
        # Calculate spatial statistics
        spatial_stats = self._calculate_spatial_statistics(fused_data, target_hexagons)
        
        # Perform spatial correlation analysis
        correlation_analysis = self._analyze_spatial_correlations(fused_data)
        
        # Identify spatial clusters
        cluster_analysis = self._identify_spatial_clusters(fused_data, target_hexagons)
        
        # Add spatial analysis results to fused data
        for hex_id in fused_data:
            if hex_id in spatial_stats:
                fused_data[hex_id]['spatial_stats'] = spatial_stats[hex_id]
            
            if hex_id in correlation_analysis:
                fused_data[hex_id]['spatial_correlations'] = correlation_analysis[hex_id]
            
            if hex_id in cluster_analysis:
                fused_data[hex_id]['spatial_cluster'] = cluster_analysis[hex_id]
        
        logger.info("âœ… Enhanced spatial analysis completed")
        return fused_data
    
    def _calculate_spatial_statistics(self, fused_data: Dict[str, Any], 
                                    target_hexagons: List[str]) -> Dict[str, Any]:
        """
        Calculate spatial statistics for each hexagon.
        
        Args:
            fused_data: Fused H3 data
            target_hexagons: List of target hexagons
            
        Returns:
            Dictionary of spatial statistics by hexagon
        """
        spatial_stats = {}
        
        for hex_id in target_hexagons:
            if hex_id not in fused_data:
                continue
            
            try:
                # Get hexagon center and area
                center_lat, center_lng = cell_to_latlng(hex_id)
                area_km2 = cell_area(hex_id, unit='km^2')
                
                # Get neighboring hexagons
                neighbors = grid_disk(hex_id, 1)
                neighbor_count = len(neighbors)
                
                # Calculate data density
                hex_data = fused_data[hex_id]
                data_sources = list(hex_data.keys()) if isinstance(hex_data, dict) else []
                source_count = len(data_sources)
                
                # Calculate feature density
                total_features = 0
                if isinstance(hex_data, dict):
                    for source_data in hex_data.values():
                        if isinstance(source_data, list):
                            total_features += len(source_data)
                        else:
                            total_features += 1
                
                spatial_stats[hex_id] = {
                    'center_lat': center_lat,
                    'center_lng': center_lng,
                    'area_km2': area_km2,
                    'neighbor_count': neighbor_count,
                    'data_source_count': source_count,
                    'feature_count': total_features,
                    'feature_density': total_features / area_km2 if area_km2 > 0 else 0
                }
                
            except Exception as e:
                logger.warning(f"Error calculating spatial stats for {hex_id}: {e}")
                continue
        
        return spatial_stats
    
    def _analyze_spatial_correlations(self, fused_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Analyze spatial correlations between data sources.
        
        Args:
            fused_data: Fused H3 data
            
        Returns:
            Dictionary of spatial correlation analysis by hexagon
        """
        correlation_analysis = {}
        
        # This is a simplified correlation analysis
        # In a full implementation, you would calculate actual statistical correlations
        
        for hex_id, hex_data in fused_data.items():
            if not isinstance(hex_data, dict):
                continue
            
            try:
                # Calculate correlation metrics
                data_sources = list(hex_data.keys())
                source_count = len(data_sources)
                
                # Simple correlation indicators
                correlation_indicators = {
                    'data_source_count': source_count,
                    'has_multiple_sources': source_count > 1,
                    'source_diversity': source_count / 4.0  # Normalized to max expected sources
                }
                
                correlation_analysis[hex_id] = correlation_indicators
                
            except Exception as e:
                logger.warning(f"Error analyzing correlations for {hex_id}: {e}")
                continue
        
        return correlation_analysis
    
    def _identify_spatial_clusters(self, fused_data: Dict[str, Any], 
                                 target_hexagons: List[str]) -> Dict[str, Any]:
        """
        Identify spatial clusters in the data.
        
        Args:
            fused_data: Fused H3 data
            target_hexagons: List of target hexagons
            
        Returns:
            Dictionary of cluster analysis by hexagon
        """
        cluster_analysis = {}
        
        # Simple clustering based on data density
        high_density_hexagons = []
        
        for hex_id, hex_data in fused_data.items():
            try:
                # Calculate data density
                if isinstance(hex_data, dict):
                    total_features = sum(
                        len(source_data) if isinstance(source_data, list) else 1
                        for source_data in hex_data.values()
                    )
                else:
                    total_features = 1
                
                # Identify high-density areas
                if total_features > 5:  # Threshold for high density
                    high_density_hexagons.append(hex_id)
                
                cluster_analysis[hex_id] = {
                    'feature_count': total_features,
                    'is_high_density': total_features > 5,
                    'cluster_type': 'high_density' if total_features > 5 else 'low_density'
                }
                
            except Exception as e:
                logger.warning(f"Error identifying clusters for {hex_id}: {e}")
                continue
        
        return cluster_analysis
    
    def _generate_fusion_report(self, fused_data: Dict[str, Any], 
                               data_sources: Dict[str, Any], 
                               target_hexagons: List[str]) -> Dict[str, Any]:
        """
        Generate comprehensive fusion report.
        
        Args:
            fused_data: Fused H3 data
            data_sources: Original data sources
            target_hexagons: List of target hexagons
            
        Returns:
            Fusion report dictionary
        """
        report = {
            'timestamp': datetime.now().isoformat(),
            'fusion_summary': {
                'total_target_hexagons': len(target_hexagons),
                'fused_hexagons': len(fused_data),
                'coverage_percentage': len(fused_data) / len(target_hexagons) * 100 if target_hexagons else 0,
                'data_sources_processed': len(data_sources)
            },
            'data_source_summary': {},
            'spatial_analysis': {
                'enabled': self.enable_spatial_analysis,
                'spatial_stats_calculated': len(fused_data),
                'correlation_analysis_performed': self.enable_spatial_analysis,
                'cluster_analysis_performed': self.enable_spatial_analysis
            },
            'quality_metrics': {
                'validation_passed': True,
                'spatial_consistency': True,
                'data_integrity': True
            }
        }
        
        # Add data source summaries
        for source_name, source_data in data_sources.items():
            report['data_source_summary'][source_name] = {
                'hexagon_count': len(source_data),
                'feature_count': sum(
                    len(hex_data) if isinstance(hex_data, list) else 1
                    for hex_data in source_data.values()
                )
            }
        
        return report
    
    def validate_h3_operations(self) -> Dict[str, Any]:
        """
        Validate H3 operations and API usage.
        
        Returns:
            Validation result dictionary
        """
        validation_result = {
            'h3_api_version': '4.x',
            'space_integration': SPACE_H3_AVAILABLE,
            'operations_tested': [],
            'errors': [],
            'warnings': []
        }
        
        try:
            # Test basic H3 operations
            test_lat, test_lng = 41.7, -124.0  # Del Norte County coordinates
            test_resolution = 8
            
            # Test latlng_to_cell
            test_cell = latlng_to_cell(test_lat, test_lng, test_resolution)
            validation_result['operations_tested'].append('latlng_to_cell')
            
            # Test cell_to_latlng
            reverse_lat, reverse_lng = cell_to_latlng(test_cell)
            validation_result['operations_tested'].append('cell_to_latlng')
            
            # Test cell_to_latlng_boundary
            boundary = cell_to_latlng_boundary(test_cell)
            validation_result['operations_tested'].append('cell_to_latlng_boundary')
            
            # Test geo_to_cells
            test_polygon = {
                'type': 'Polygon',
                'coordinates': [[[test_lng-0.1, test_lat-0.1], [test_lng+0.1, test_lat-0.1], 
                               [test_lng+0.1, test_lat+0.1], [test_lng-0.1, test_lat+0.1], 
                               [test_lng-0.1, test_lat-0.1]]]
            }
            cells = geo_to_cells(test_polygon, test_resolution)
            validation_result['operations_tested'].append('geo_to_cells')
            
            # Test grid_disk
            neighbors = grid_disk(test_cell, 1)
            validation_result['operations_tested'].append('grid_disk')
            
            # Test cell_area
            area = cell_area(test_cell, unit='km^2')
            validation_result['operations_tested'].append('cell_area')
            
            # Test is_valid_cell
            is_valid = is_valid_cell(test_cell)
            validation_result['operations_tested'].append('is_valid_cell')
            
            logger.info("âœ… H3 operations validation completed successfully")
            
        except Exception as e:
            validation_result['errors'].append(f"H3 validation failed: {e}")
            logger.error(f"âŒ H3 validation failed: {e}")
        
        return validation_result

def create_enhanced_h3_fusion(h3_resolution: int = 8, enable_spatial_analysis: bool = True, cache_dir: Optional[Path] = None) -> EnhancedH3Fusion:
    """
    Factory function to create an enhanced H3 fusion engine.
    
    Args:
        h3_resolution: H3 resolution for spatial indexing
        enable_spatial_analysis: Enable advanced spatial analysis
        
    Returns:
        Configured EnhancedH3Fusion instance
    """
    return EnhancedH3Fusion(h3_resolution, enable_spatial_analysis, cache_dir)
