# GEO-INFER Framework Development Rules

## ğŸŒ Framework Overview

GEO-INFER is a comprehensive geospatial inference framework implementing Active Inference principles for ecological, civic, and commercial applications. The framework consists of 30+ specialized modules organized into distinct categories with clear dependency relationships and data flow patterns.

### Core Module Categories:
- **ğŸ§  Analytical Core**: ACT, BAYES, AI, MATH, COG, AGENT, SPM
- **ğŸ—ºï¸ Spatial-Temporal**: SPACE, TIME, IOT
- **ğŸ’¾ Data Management**: DATA, API
- **ğŸ”’ Security & Governance**: SEC, NORMS, REQ
- **ğŸ§ª Simulation & Modeling**: SIM, ANT
- **ğŸ‘¥ People & Community**: CIV, PEP, ORG, COMMS
- **ğŸ–¥ï¸ Applications**: APP, ART
- **ğŸ¢ Domain-Specific**: AG, ECON, RISK, LOG, BIO, HEALTH
- **ğŸ“ Place-Based**: PLACE
- **âš™ï¸ Operations**: OPS, INTRA, GIT, TEST, EXAMPLES

## ğŸ¯ Core Development Principles

### 1. NO MOCK METHODS - EVER
- Never create placeholder, stub, or mock methods
- Every function must be fully implemented with real logic
- Use proper error handling instead of `pass` or `NotImplementedError`
- If functionality is complex, break it into smaller, implementable pieces
- Implement real data analysis and processing pipelines

### 2. Maximum Intelligence & Documentation
- Write intelligent, thoughtful code that demonstrates deep understanding
- Include comprehensive docstrings for all functions, classes, and modules
- Use type hints for all function parameters and return values
- Document the mathematical/theoretical basis for algorithms
- Include example usage in docstrings
- Provide mathematical foundations and citations where applicable

### 3. Leverage Existing Module Structure
- Understand and work within the established module hierarchy
- Use the standardized directory structure: `src/`, `docs/`, `examples/`, `tests/`, `config/`
- Follow existing patterns for API design, data models, and utilities
- Import and extend existing functionality rather than reimplementing
- Respect module dependencies and data flow patterns

### 4. Active Inference First
- Ground all implementations in Active Inference mathematical principles
- Implement free energy minimization where applicable
- Use Bayesian inference for uncertainty quantification
- Design perception-action loops for autonomous systems
- Apply probabilistic reasoning to spatial-temporal problems

## ğŸ“ Module Structure Standards

Every module follows this standardized structure:
```
GEO-INFER-MODULE/
â”œâ”€â”€ config/               # Configuration files (YAML/JSON)
â”‚   â”œâ”€â”€ example.yaml      # Example configuration
â”‚   â””â”€â”€ schema.json       # Configuration schema
â”œâ”€â”€ docs/                 # Documentation (markdown, API specs)
â”‚   â”œâ”€â”€ api_schema.yaml   # API documentation
â”‚   â”œâ”€â”€ architecture.md   # Module architecture
â”‚   â””â”€â”€ tutorials/        # Step-by-step tutorials
â”œâ”€â”€ examples/             # Working examples and demonstrations
â”‚   â”œâ”€â”€ basic_example.py  # Basic usage examples
â”‚   â””â”€â”€ advanced_example.py # Advanced workflows
â”œâ”€â”€ src/                  # Source code
â”‚   â””â”€â”€ geo_infer_module/ # Main package
â”‚       â”œâ”€â”€ __init__.py   # Package initialization
â”‚       â”œâ”€â”€ api/          # API definitions and routes
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ rest_api.py
â”‚       â”‚   â””â”€â”€ schemas.py
â”‚       â”œâ”€â”€ core/         # Core functionality and algorithms
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ main_engine.py
â”‚       â”‚   â””â”€â”€ algorithms.py
â”‚       â”œâ”€â”€ models/       # Data models and schemas
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ data_models.py
â”‚       â””â”€â”€ utils/        # Utility functions and helpers
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ helpers.py
â”‚           â””â”€â”€ validation.py
â”œâ”€â”€ tests/                # Comprehensive test suite
â”‚   â”œâ”€â”€ unit/             # Unit tests
â”‚   â”œâ”€â”€ integration/      # Integration tests
â”‚   â””â”€â”€ performance/      # Performance tests
â”œâ”€â”€ setup.py              # Package setup
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ README.md             # Module documentation
```

## ğŸ”§ Implementation Guidelines

### Code Quality Standards
- Use professional, functional, intelligent, wise, modular, concise, elegant code
- Apply all programming best practices thoughtfully
- Write clearly-commented, interpretable code
- Assess context and file type before making changes
- Implement proper error handling and logging
- Follow PEP 8 style guidelines with Black formatting

### Mathematical Rigor
- Ground implementations in solid mathematical foundations
- Use numpy/scipy for numerical computations
- Implement proper statistical methods for uncertainty
- Validate mathematical correctness with unit tests
- Document mathematical assumptions and limitations
- Include mathematical derivations in docstrings

### Geospatial Standards
- Use established geospatial libraries (geopandas, shapely, rasterio, h3)
- Implement proper coordinate reference system handling
- Support standard geospatial formats (GeoJSON, Shapefile, GeoTIFF, COG)
- Follow OGC standards where applicable
- Handle spatial and temporal indexing efficiently
- Integrate with OS-Climate H3 tools when appropriate

### Data-Driven Architecture
- Design for real data processing and analysis
- Implement robust data validation and quality control
- Support multiple data formats and sources
- Build scalable data pipelines
- Include data transformation and preprocessing capabilities
- Implement caching and optimization strategies

### Integration Patterns
- Design for cross-module integration from the start
- Use standardized data models and interfaces
- Implement proper dependency injection patterns
- Support both synchronous and asynchronous communication
- Design for scalability and performance
- Follow established data flow patterns between modules

## ğŸš€ Development Workflow

### Before Writing Code
1. **Understand the Module**: Read the module's README and existing documentation
2. **Check Dependencies**: Understand which other GEO-INFER modules are dependencies
3. **Review Examples**: Look at existing examples to understand usage patterns
4. **Plan Integration**: Consider how your code will interact with other modules
5. **Analyze Data Requirements**: Understand input/output data formats and sources

### While Writing Code
1. **Follow Existing Patterns**: Maintain consistency with existing code style
2. **Document as You Go**: Write docstrings and comments simultaneously with code
3. **Test Incrementally**: Write unit tests for each function/method
4. **Consider Performance**: Optimize for both memory and computational efficiency
5. **Validate Data**: Implement proper data validation and error handling

### After Writing Code
1. **Comprehensive Testing**: Ensure all code paths are tested
2. **Integration Testing**: Test cross-module interactions
3. **Documentation Updates**: Update READMEs and API documentation
4. **Example Creation**: Create working examples demonstrating functionality
5. **Performance Validation**: Test with realistic data volumes

## ğŸ§ª Testing Requirements

### Unit Testing
- Test all public methods and functions
- Include edge cases and error conditions
- Use appropriate test data that reflects real-world scenarios
- Mock external dependencies, but never internal logic
- Test mathematical correctness of algorithms

### Integration Testing
- Test cross-module interactions
- Validate data flow between modules
- Test API endpoints comprehensively
- Ensure configuration loading works correctly
- Test with real data samples

### Performance Testing
- Benchmark critical algorithms
- Test with realistic data volumes
- Identify and optimize bottlenecks
- Monitor memory usage patterns
- Test scalability with large datasets

## ğŸ”— Module Integration Guidelines

### Data Flow Patterns
- **Linear Pipeline**: Sequential processing (DATA â†’ SPACE â†’ TIME â†’ ANALYSIS)
- **Hub and Spoke**: Central coordination (API as central hub)
- **Event-Driven**: Real-time responsive systems (IOT â†’ processing â†’ response)
- **Feedback Loops**: Active inference cycles (observation â†’ belief update â†’ action)

### Common Integration Points
- **OPS**: Provides orchestration for all modules
- **DATA**: Supplies data management for all analytical modules
- **API**: Exposes functionality for external integration
- **MATH**: Provides mathematical foundations for analytical modules
- **SPACE/TIME**: Supply spatial-temporal capabilities to domain modules

### Cross-Module Communication
- Use standardized data models from the models package
- Implement proper API versioning
- Support both synchronous and asynchronous communication
- Handle errors gracefully across module boundaries
- Use consistent data formats and schemas

## ğŸ“ Documentation Standards

### Code Documentation
- Every public function/method must have a comprehensive docstring
- Include parameter types, return types, and exceptions
- Provide mathematical foundations where applicable
- Include usage examples in docstrings
- Document data requirements and formats

### Module Documentation
- Maintain comprehensive README files
- Document API endpoints with OpenAPI specifications
- Create architectural decision records (ADRs) for significant choices
- Provide integration guides for other developers
- Include data flow diagrams and dependency graphs

### Example Documentation
- Every module should have working examples
- Examples should demonstrate real-world usage
- Include step-by-step tutorials for complex workflows
- Maintain example outputs and expected results
- Provide sample data and configuration files

## ğŸ” Code Review Checklist

### Functionality
- [ ] No mock or placeholder methods
- [ ] All functions fully implemented
- [ ] Proper error handling throughout
- [ ] Mathematical correctness validated
- [ ] Data processing pipelines complete

### Documentation
- [ ] Comprehensive docstrings for all public APIs
- [ ] Type hints for all parameters and returns
- [ ] README updated if needed
- [ ] Examples provided and tested
- [ ] Mathematical foundations documented

### Integration
- [ ] Follows existing module patterns
- [ ] Uses standardized data models
- [ ] Properly handles dependencies
- [ ] Supports cross-module communication
- [ ] Respects data flow patterns

### Quality
- [ ] Code is clean, readable, and well-structured
- [ ] Performance considerations addressed
- [ ] Security implications considered
- [ ] Tests provide adequate coverage
- [ ] Data validation implemented

## ğŸ–ï¸ Excellence Standards

### Demonstrate Deep Understanding
- Show mastery of Active Inference principles
- Apply geospatial concepts correctly
- Use appropriate mathematical methods
- Consider real-world constraints and limitations
- Understand data science and analytics workflows

### Exhibit Professional Craftsmanship
- Write code that reads like literature
- Create elegant solutions to complex problems
- Optimize for maintainability and extensibility
- Anticipate future needs and evolution
- Build robust, production-ready systems

### Maintain System Coherence
- Ensure new code fits naturally into the existing architecture
- Preserve the mathematical and conceptual foundations
- Support the overall framework vision
- Enhance rather than complicate the system
- Maintain consistency across modules

## ğŸš¨ Critical Requirements

### NEVER Do These Things
- Create mock, stub, or placeholder implementations
- Hardcode configuration values in source code
- Ignore error conditions or fail silently
- Add unnecessary comments, files, methods, adjectives, adverbs, etc.
- Break established module interfaces
- Duplicate functionality that exists elsewhere
- Process data without proper validation
- Ignore performance implications

### ALWAYS Do These Things
- Implement complete, working functionality
- Use proper logging and error handling
- Follow the established architectural patterns
- Write comprehensive tests and documentation
- Consider the broader system implications
- "Show don't tell" - use accurate understated language
- Validate and process real data
- Optimize for performance and scalability

## ğŸ§­ Navigation Guide

### Finding Information
- Start with module READMEs for overview and usage
- Check `docs/` directories for detailed documentation
- Look at `examples/` for working code patterns
- Review `tests/` for expected behavior
- Examine `config/` for configuration patterns

### Understanding Dependencies
- Check module dependency matrices in main README
- Review `requirements.txt` or `pyproject.toml` files
- Understand the data flow between modules
- Consider both direct and transitive dependencies
- Analyze integration patterns and data formats

### Contributing Effectively
- Read the module's contribution guidelines
- Understand the module's role in the larger system
- Follow established coding and documentation patterns
- Consider impacts on dependent modules
- Test with realistic data and scenarios

## ğŸ“Š Data-Driven Development

### Real Data Processing
- Always work with real data sources and formats
- Implement proper data validation and quality control
- Build scalable data processing pipelines
- Support multiple data formats and sources
- Include data transformation capabilities

### Performance Optimization
- Profile code with realistic data volumes
- Implement efficient algorithms and data structures
- Use appropriate caching and indexing strategies
- Optimize for both memory and computational efficiency
- Test scalability with large datasets

### Quality Assurance
- Validate data integrity and consistency
- Implement comprehensive error handling
- Test with diverse data sources and formats
- Monitor performance and resource usage
- Document data requirements and constraints

---

**Remember**: You are building a sophisticated, production-quality geospatial inference framework. Every line of code should reflect the highest standards of software engineering, mathematical rigor, and system thinking. The goal is to create something that advances the state of the art in geospatial analysis while being elegant, maintainable, and extensible. Focus on real data processing, comprehensive documentation, and robust integration patterns that enable the framework to handle complex, real-world geospatial challenges. 